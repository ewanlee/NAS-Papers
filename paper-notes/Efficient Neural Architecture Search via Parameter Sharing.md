这篇论文是NAS的进阶版，我觉得其实就是NASNet的一种改进。其中心思想在于，将搜索空间固定在一个有向无环图中，这个图中的顶点代表
具体操作，根据设计的是CNN还是RNN有所不同，然后边就代表层与层之间的连接。重点在于有向图，这个图中的顶点是有序号的，一条边只能从
序号靠前的顶点出发，终止于序号靠后的顶点。

那么为什么ENAS能够只用一张1080Ti就能在16个小时之内训练出一个很好的网络呢？精髓就在于参数共享，由于强化学习算法在搜索空间，也就是
这个有向无环图中进行搜索，每一次选取的边以及顶点上的操作都各不相同，但是，如果强化算法之前进行某次采样时对某条边上的参数进行了训练，
那么之后某一次采样又采到这条边时，参数就不是初始化了，而是直接用之前训练好的参数。意思就是说，对于强化算法来说有一个全局的参数库，
每一次搜索都是从这个参数库中选取一些参数，更新之后又写回到参数库中。

所以训练的流程可以叙述如下：首先强化学习的控制器还是一个RNN，它有一套参数w，然后共享参数库里是另一套参数theta。首先我们固定w，然后
采样出一些网络结构，我们训练这些结构（注意，只要这些结构有公共边，那么这些边的参数就是互相共享的，只有一个总的全局参数库）直到收敛
（其实是400个step），根据最后得到的reward来更新w。之后继续重复上述过程，强化算法和NAS论文一样。这里有个很有意思的地方，由于每个采样出的
网络都有一个reward， 最后用策略梯度来更新w的时候，实验表明虽然理论上方差会很大，但是batch=1同样能取得很好的效果！
还有一点值得说明的是训练完成以后最终的网络怎么获得。论文采用的方式是先采样出一堆网络，然后对每个网络从验证集中拿出一个batch在上面进行性能测试，
选准确率最高的网络继续训练。这个和一般的方法还真有些不一样，论文也说一般用的方法是选出一堆网络每个都直接在训练集上继续训练直到收敛，
最后选个最好的，但是很明显前一种方法耗费的资源要小得多，虽然感觉上只在验证集的一个batch测试有点不靠谱，但是实验表明性能还真没差多少。
我感觉原因应该是最后采样出的网络性能其实都差不多吧 = =

下面分别讲一下每种网络的搜索空间都是什么样的，我就贴几张图，不细讲了，看图其实就能明白个大概。

首先是RNN：

![](http://o7ie0tcjk.bkt.clouddn.com/ojdhoqzur8kbxv6z.jpg)

然后是CNN，这里CNN有两种方式，一种是直接训练整个网络，另外一种就是像NASNet那样训练Cell然后堆叠起来：

![](http://o7ie0tcjk.bkt.clouddn.com/zwto7k8zm67x7kzx.jpg)

注意这里不像RNN只能从之前的顶点里选一条边，而是任意条，搜索空间一下子大了好多。

另一种方法：

![](http://o7ie0tcjk.bkt.clouddn.com/hcxg3oebxzscmnu9.jpg)

我看到这张图就觉得ENAS其实就是NASNet的扩展版，就是将NASNet Block之间的所有连接的可能都存起来，然后从里面进行采样。

论文最后提到比较重要的一点就是之前的论文结果都表明只要搜索空间设置的好，随机策略都能取得比较好的效果。但是本文最后表明
随机效果比较差，我感觉原因是因为ENAS的搜索空间要比NASNet还有NAS要大一些，但是因为参数共享所以能够应付这么大的空间；反而随机策略
因为搜索空间过大就无法取得好的效果了。
